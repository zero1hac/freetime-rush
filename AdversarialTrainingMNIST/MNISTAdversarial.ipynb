{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Cleverhans tutotial for generating adversarial images and adversarial training.\n",
    "'''\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import app\n",
    "from tensorflow.python.platform import flags\n",
    "\n",
    "from cleverhans.utils_mnist import data_mnist\n",
    "from cleverhans.utils_tf import model_train, model_eval\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.utils import AccuracyReport\n",
    "from cleverhans.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP(Model):\n",
    "    \"\"\"\n",
    "    An example of a bare bones multilayer perceptron (MLP) class.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layers, input_shape):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.layer_names = []\n",
    "        self.layers = layers\n",
    "        self.input_shape = input_shape\n",
    "        if isinstance(layers[-1], Softmax):\n",
    "            layers[-1].name = 'probs'\n",
    "            layers[-2].name = 'logits'\n",
    "        else:\n",
    "            layers[-1].name = 'logits'\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if hasattr(layer, 'name'):\n",
    "                name = layer.name\n",
    "            else:\n",
    "                name = layer.__class__.__name__ + str(i)\n",
    "            self.layer_names.append(name)\n",
    "\n",
    "            layer.set_input_shape(input_shape)\n",
    "            input_shape = layer.get_output_shape()\n",
    "\n",
    "    def fprop(self, x, set_ref=False):\n",
    "        states = []\n",
    "        for layer in self.layers:\n",
    "            if set_ref:\n",
    "                layer.ref = x\n",
    "            x = layer.fprop(x)\n",
    "            assert x is not None\n",
    "            states.append(x)\n",
    "        states = dict(zip(self.get_layer_names(), states))\n",
    "        return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "\n",
    "    def get_output_shape(self):\n",
    "        return self.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "\n",
    "    def __init__(self, num_hid):\n",
    "        self.num_hid = num_hid\n",
    "\n",
    "    def set_input_shape(self, input_shape):\n",
    "        batch_size, dim = input_shape\n",
    "        self.input_shape = [batch_size, dim]\n",
    "        self.output_shape = [batch_size, self.num_hid]\n",
    "        init = tf.random_normal([dim, self.num_hid], dtype=tf.float32)\n",
    "        init = init / tf.sqrt(1e-7 + tf.reduce_sum(tf.square(init), axis=0,\n",
    "                                                   keep_dims=True))\n",
    "        self.W = tf.Variable(init)\n",
    "        self.b = tf.Variable(np.zeros((self.num_hid,)).astype('float32'))\n",
    "\n",
    "    def fprop(self, x):\n",
    "        return tf.matmul(x, self.W) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Conv2D(Layer):\n",
    "\n",
    "    def __init__(self, output_channels, kernel_shape, strides, padding):\n",
    "        self.__dict__.update(locals())\n",
    "        del self.self\n",
    "\n",
    "    def set_input_shape(self, input_shape):\n",
    "        batch_size, rows, cols, input_channels = input_shape\n",
    "        kernel_shape = tuple(self.kernel_shape) + (input_channels,\n",
    "                                                   self.output_channels)\n",
    "        assert len(kernel_shape) == 4\n",
    "        assert all(isinstance(e, int) for e in kernel_shape), kernel_shape\n",
    "        init = tf.random_normal(kernel_shape, dtype=tf.float32)\n",
    "        init = init / tf.sqrt(1e-7 + tf.reduce_sum(tf.square(init),\n",
    "                                                   axis=(0, 1, 2)))\n",
    "        self.kernels = tf.Variable(init)\n",
    "        self.b = tf.Variable(\n",
    "            np.zeros((self.output_channels,)).astype('float32'))\n",
    "        orig_input_batch_size = input_shape[0]\n",
    "        input_shape = list(input_shape)\n",
    "        input_shape[0] = 1\n",
    "        dummy_batch = tf.zeros(input_shape)\n",
    "        dummy_output = self.fprop(dummy_batch)\n",
    "        output_shape = [int(e) for e in dummy_output.get_shape()]\n",
    "        output_shape[0] = 1\n",
    "        self.output_shape = tuple(output_shape)\n",
    "\n",
    "    def fprop(self, x):\n",
    "        return tf.nn.conv2d(x, self.kernels,\n",
    "                            (1,) + tuple(self.strides) + (1,), self.padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReLU(Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def set_input_shape(self, shape):\n",
    "        self.input_shape = shape\n",
    "        self.output_shape = shape\n",
    "\n",
    "    def get_output_shape(self):\n",
    "        return self.output_shape\n",
    "\n",
    "    def fprop(self, x):\n",
    "        return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Softmax(Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def set_input_shape(self, shape):\n",
    "        self.input_shape = shape\n",
    "        self.output_shape = shape\n",
    "\n",
    "    def fprop(self, x):\n",
    "        return tf.nn.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Flatten(Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def set_input_shape(self, shape):\n",
    "        self.input_shape = shape\n",
    "        output_width = 1\n",
    "        for factor in shape[1:]:\n",
    "            output_width *= factor\n",
    "        self.output_width = output_width\n",
    "        self.output_shape = [None, output_width]\n",
    "\n",
    "    def fprop(self, x):\n",
    "        return tf.reshape(x, [-1, self.output_width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_basic_cnn(nb_filters=64, nb_classes=10,\n",
    "                   input_shape=(None, 28, 28, 1)):\n",
    "    layers = [Conv2D(nb_filters, (8, 8), (2, 2), \"SAME\"),\n",
    "              ReLU(),\n",
    "              Conv2D(nb_filters * 2, (6, 6), (2, 2), \"VALID\"),\n",
    "              ReLU(),\n",
    "              Conv2D(nb_filters * 2, (5, 5), (1, 1), \"VALID\"),\n",
    "              ReLU(),\n",
    "              Flatten(),\n",
    "              Linear(nb_classes),\n",
    "              Softmax()]\n",
    "\n",
    "    model = MLP(layers, input_shape)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mnist_tutorial(train_start=0, train_end=60000, test_start=0,\n",
    "                   test_end=10000, nb_epochs=6, batch_size=128,\n",
    "                   learning_rate=0.001, testing=False):\n",
    "    \"\"\"\n",
    "    MNIST cleverhans tutorial\n",
    "    :param train_start: index of first training set example\n",
    "    :param train_end: index of last training set example\n",
    "    :param test_start: index of first test set example\n",
    "    :param test_end: index of last test set example\n",
    "    :param nb_epochs: number of epochs to train model\n",
    "    :param batch_size: size of training batches\n",
    "    :param learning_rate: learning rate for training\n",
    "    :param testing: if true, test error is calculated\n",
    "    :return: an AccuracyReport object\n",
    "    \"\"\"\n",
    "\n",
    "    # Object used to keep track of (and return) key accuracies\n",
    "    report = AccuracyReport()\n",
    "\n",
    "    # Set TF random seed to improve reproducibility\n",
    "    tf.set_random_seed(1234)\n",
    "\n",
    "    # Create TF session\n",
    "    sess = tf.Session()\n",
    "\n",
    "    # Get MNIST test data\n",
    "    X_train, Y_train, X_test, Y_test = data_mnist(train_start=train_start,\n",
    "                                                  train_end=train_end,\n",
    "                                                  test_start=test_start,\n",
    "                                                  test_end=test_end)\n",
    "\n",
    "    # Use label smoothing\n",
    "    assert Y_train.shape[1] == 10.\n",
    "    label_smooth = .1\n",
    "    Y_train = Y_train.clip(label_smooth / 9., 1. - label_smooth)\n",
    "\n",
    "    # Define input TF placeholder\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "    # Define TF model graph\n",
    "    model = make_basic_cnn()\n",
    "    preds = model.get_probs(x)\n",
    "    print(\"Defined TensorFlow model graph.\")\n",
    "\n",
    "    def evaluate():\n",
    "        # Evaluate the accuracy of the MNIST model on legitimate test examples\n",
    "        eval_params = {'batch_size': batch_size}\n",
    "        acc = model_eval(sess, x, y, preds, X_test, Y_test, args=eval_params)\n",
    "        report.clean_train_clean_eval = acc\n",
    "        assert X_test.shape[0] == test_end - test_start, X_test.shape\n",
    "        print('Test accuracy on legitimate examples: %0.4f' % acc)\n",
    "\n",
    "    model_path = \"models/mnist\"\n",
    "    # Train an MNIST model\n",
    "    train_params = {\n",
    "        'nb_epochs': nb_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': learning_rate\n",
    "    }\n",
    "    model_train(sess, x, y, preds, X_train, Y_train, evaluate=evaluate,\n",
    "                args=train_params)\n",
    "\n",
    "    # Calculate training error\n",
    "    if testing:\n",
    "        eval_params = {'batch_size': batch_size}\n",
    "        acc = model_eval(sess, x, y, preds, X_train, Y_train, args=eval_params)\n",
    "        report.train_clean_train_clean_eval = acc\n",
    "\n",
    "    # Initialize the Fast Gradient Sign Method (FGSM) attack object and graph\n",
    "    fgsm = FastGradientMethod(model, sess=sess)\n",
    "    fgsm_params = {'eps': 0.3}\n",
    "\n",
    "    adv_x = fgsm.generate(x, **fgsm_params)\n",
    "    preds_adv = model.get_probs(adv_x)\n",
    "\n",
    "    # Evaluate the accuracy of the MNIST model on adversarial examples\n",
    "    eval_par = {'batch_size': batch_size}\n",
    "    acc = model_eval(sess, x, y, preds_adv, X_test, Y_test, args=eval_par)\n",
    "    print('Test accuracy on adversarial examples: %0.4f\\n' % acc)\n",
    "    report.clean_train_adv_eval = acc\n",
    "\n",
    "    # Calculate training error\n",
    "    if testing:\n",
    "        eval_par = {'batch_size': batch_size}\n",
    "        acc = model_eval(sess, x, y, preds_adv, X_train,\n",
    "                         Y_train, args=eval_par)\n",
    "        report.train_clean_train_adv_eval = acc\n",
    "\n",
    "    print(\"Repeating the process, using adversarial training\")\n",
    "    # Redefine TF model graph\n",
    "    model_2 = make_basic_cnn()\n",
    "    preds_2 = model_2(x)\n",
    "    fgsm2 = FastGradientMethod(model_2, sess=sess)\n",
    "    preds_2_adv = model_2(fgsm2.generate(x, **fgsm_params))\n",
    "\n",
    "    def evaluate_2():\n",
    "        # Accuracy of adversarially trained model on legitimate test inputs\n",
    "        eval_params = {'batch_size': batch_size}\n",
    "        accuracy = model_eval(sess, x, y, preds_2, X_test, Y_test,\n",
    "                              args=eval_params)\n",
    "        print('Test accuracy on legitimate examples: %0.4f' % accuracy)\n",
    "        report.adv_train_clean_eval = accuracy\n",
    "\n",
    "        # Accuracy of the adversarially trained model on adversarial examples\n",
    "        accuracy = model_eval(sess, x, y, preds_2_adv, X_test,\n",
    "                              Y_test, args=eval_params)\n",
    "        print('Test accuracy on adversarial examples: %0.4f' % accuracy)\n",
    "        report.adv_train_adv_eval = accuracy\n",
    "\n",
    "    # Perform and evaluate adversarial training\n",
    "    model_train(sess, x, y, preds_2, X_train, Y_train,\n",
    "                predictions_adv=preds_2_adv, evaluate=evaluate_2,\n",
    "                args=train_params)\n",
    "\n",
    "    # Calculate training errors\n",
    "    if testing:\n",
    "        eval_params = {'batch_size': batch_size}\n",
    "        accuracy = model_eval(sess, x, y, preds_2, X_train, Y_train,\n",
    "                              args=eval_params)\n",
    "        report.train_adv_train_clean_eval = accuracy\n",
    "        accuracy = model_eval(sess, x, y, preds_2_adv, X_train,\n",
    "                              Y_train, args=eval_params)\n",
    "        report.train_adv_train_adv_eval = accuracy\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags.DEFINE_integer('nb_epochs', 6, 'Number of epochs to train model')\n",
    "flags.DEFINE_integer('batch_size', 128, 'Size of training batches')\n",
    "flags.DEFINE_float('learning_rate', 0.001, 'Learning rate for training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/t10k-labels-idx1-ubyte.gz\n",
      "X_train shape: (60000, 28, 28, 1)\n",
      "X_test shape: (10000, 28, 28, 1)\n",
      "Defined TensorFlow model graph.\n",
      "Epoch 0\n",
      "\tEpoch took 211.96022892 seconds\n",
      "Test accuracy on legitimate examples: 0.9886\n",
      "Epoch 1\n",
      "\tEpoch took 211.769145966 seconds\n",
      "Test accuracy on legitimate examples: 0.9911\n",
      "Epoch 2\n",
      "\tEpoch took 212.651267052 seconds\n",
      "Test accuracy on legitimate examples: 0.9925\n",
      "Epoch 3\n",
      "\tEpoch took 212.574196815 seconds\n",
      "Test accuracy on legitimate examples: 0.9928\n",
      "Epoch 4\n",
      "\tEpoch took 213.347193956 seconds\n",
      "Test accuracy on legitimate examples: 0.9928\n",
      "Epoch 5\n",
      "\tEpoch took 212.534152985 seconds\n",
      "Test accuracy on legitimate examples: 0.9925\n",
      "Completed model training.\n",
      "Test accuracy on adversarial examples: 0.0431\n",
      "\n",
      "Repeating the process, using adversarial training\n",
      "Epoch 0\n",
      "\tEpoch took 469.869373798 seconds\n",
      "Test accuracy on legitimate examples: 0.9834\n",
      "Test accuracy on adversarial examples: 0.8135\n",
      "Epoch 1\n",
      "\tEpoch took 486.77530694 seconds\n",
      "Test accuracy on legitimate examples: 0.9898\n",
      "Test accuracy on adversarial examples: 0.9370\n",
      "Epoch 2\n",
      "\tEpoch took 531.124754906 seconds\n",
      "Test accuracy on legitimate examples: 0.9906\n",
      "Test accuracy on adversarial examples: 0.9618\n",
      "Epoch 3\n",
      "\tEpoch took 594.325844049 seconds\n",
      "Test accuracy on legitimate examples: 0.9919\n",
      "Test accuracy on adversarial examples: 0.9731\n",
      "Epoch 4\n",
      "\tEpoch took 540.200280905 seconds\n",
      "Test accuracy on legitimate examples: 0.9918\n",
      "Test accuracy on adversarial examples: 0.9770\n",
      "Epoch 5\n",
      "\tEpoch took 491.790886164 seconds\n",
      "Test accuracy on legitimate examples: 0.9924\n",
      "Test accuracy on adversarial examples: 0.9811\n",
      "Completed model training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cleverhans.utils.AccuracyReport at 0x7f70cbf3f290>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_tutorial(nb_epochs=FLAGS.nb_epochs, batch_size=FLAGS.batch_size,learning_rate=FLAGS.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
